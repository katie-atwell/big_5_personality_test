{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the Big Five Personality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was found on [Kaggle](https://www.kaggle.com/tunguz/big-five-personality-test). It contains 1,015,342 questionnaire answers collected online by [Open Psychometrics](https://openpsychometrics.org/tests/IPIP-BFFM/). The questionnaire used 50 items to measure five personality traits; openness to experience, conscientiousness, extraversion, agreeableness and neuroticism. Participants were asked to respond to each item (e.g. \"I am always prepared) on a scale of 1-5 (1=Disagree, 3=Neutral, and 5=Agree). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>dateload</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>IPC</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:01</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.5448</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:20</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>MY</td>\n",
       "      <td>3.1698</td>\n",
       "      <td>101.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:56</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>54.9119</td>\n",
       "      <td>-1.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:02:02</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.75</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:02:57</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>KE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
       "0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   \n",
       "1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   \n",
       "2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   \n",
       "3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   \n",
       "4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   \n",
       "\n",
       "              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n",
       "0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n",
       "1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n",
       "2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n",
       "3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n",
       "4  2016-03-03 02:02:57   1366.0    768.0          8.0       315.0         17   \n",
       "\n",
       "   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "0    1       GB               51.5448                 0.1991  \n",
       "1    1       MY                3.1698                101.706  \n",
       "2    1       GB               54.9119                -1.3833  \n",
       "3    1       GB                 51.75                  -1.25  \n",
       "4    2       KE                   1.0                   38.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/data-final.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A .txt file containing details of the data was also downloaded from Kaggle along with the dataset. Here you can find the questions that were asked of the participants and additional data that was collected (e.g. dateload - the timestamp from when the questionnaire was started). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data was collected (2016-2018) through an interactive on-line personality test.\n",
      "\n",
      "The personality test was constructed with the \"Big-Five Factor Markers\" from the IPIP. https://ipip.ori.org/newBigFive5broadKey.htm\n",
      "\n",
      "Participants were informed that their responses would be recorded and used for research at the beginning of the test, and asked to confirm their consent at the end of the test.\n",
      "\n",
      "\n",
      "\n",
      "The following items were presented on one page and each was rated on a five point scale using radio buttons. The order on page was was EXT1, AGR1, CSN1, EST1, OPN1, EXT2, etc.\n",
      "\n",
      "The scale was labeled 1=Disagree, 3=Neutral, 5=Agree\n",
      "\n",
      "\n",
      "\n",
      "EXT1\tI am the life of the party.\n",
      "\n",
      "EXT2\tI don't talk a lot.\n",
      "\n",
      "EXT3\tI feel comfortable around people.\n",
      "\n",
      "EXT4\tI keep in the background.\n",
      "\n",
      "EXT5\tI start conversations.\n",
      "\n",
      "EXT6\tI have little to say.\n",
      "\n",
      "EXT7\tI talk to a lot of different people at parties.\n",
      "\n",
      "EXT8\tI don't like to draw attention to myself.\n",
      "\n",
      "EXT9\tI don't mind being the center of attention.\n",
      "\n",
      "EXT10\tI am quiet around strangers.\n",
      "\n",
      "EST1\tI get stressed out easily.\n",
      "\n",
      "EST2\tI am relaxed most of the time.\n",
      "\n",
      "EST3\tI worry about things.\n",
      "\n",
      "EST4\tI seldom feel blue.\n",
      "\n",
      "EST5\tI am easily disturbed.\n",
      "\n",
      "EST6\tI get upset easily.\n",
      "\n",
      "EST7\tI change my mood a lot.\n",
      "\n",
      "EST8\tI have frequent mood swings.\n",
      "\n",
      "EST9\tI get irritated easily.\n",
      "\n",
      "EST10\tI often feel blue.\n",
      "\n",
      "AGR1\tI feel little concern for others.\n",
      "\n",
      "AGR2\tI am interested in people.\n",
      "\n",
      "AGR3\tI insult people.\n",
      "\n",
      "AGR4\tI sympathize with others' feelings.\n",
      "\n",
      "AGR5\tI am not interested in other people's problems.\n",
      "\n",
      "AGR6\tI have a soft heart.\n",
      "\n",
      "AGR7\tI am not really interested in others.\n",
      "\n",
      "AGR8\tI take time out for others.\n",
      "\n",
      "AGR9\tI feel others' emotions.\n",
      "\n",
      "AGR10\tI make people feel at ease.\n",
      "\n",
      "CSN1\tI am always prepared.\n",
      "\n",
      "CSN2\tI leave my belongings around.\n",
      "\n",
      "CSN3\tI pay attention to details.\n",
      "\n",
      "CSN4\tI make a mess of things.\n",
      "\n",
      "CSN5\tI get chores done right away.\n",
      "\n",
      "CSN6\tI often forget to put things back in their proper place.\n",
      "\n",
      "CSN7\tI like order.\n",
      "\n",
      "CSN8\tI shirk my duties.\n",
      "\n",
      "CSN9\tI follow a schedule.\n",
      "\n",
      "CSN10\tI am exacting in my work.\n",
      "\n",
      "OPN1\tI have a rich vocabulary.\n",
      "\n",
      "OPN2\tI have difficulty understanding abstract ideas.\n",
      "\n",
      "OPN3\tI have a vivid imagination.\n",
      "\n",
      "OPN4\tI am not interested in abstract ideas.\n",
      "\n",
      "OPN5\tI have excellent ideas.\n",
      "\n",
      "OPN6\tI do not have a good imagination.\n",
      "\n",
      "OPN7\tI am quick to understand things.\n",
      "\n",
      "OPN8\tI use difficult words.\n",
      "\n",
      "OPN9\tI spend time reflecting on things.\n",
      "\n",
      "OPN10\tI am full of ideas.\n",
      "\n",
      "\n",
      "\n",
      "The time spent on each question is also recorded in milliseconds. These are the variables ending in _E. This was calculated by taking the time when the button for the question was clicked minus the time of the most recent other button click.\n",
      "\n",
      "\n",
      "\n",
      "dateload    The timestamp when the survey was started.\n",
      "\n",
      "screenw     The width the of user's screen in pixels\n",
      "\n",
      "screenh     The height of the user's screen in pixels\n",
      "\n",
      "introelapse The time in seconds spent on the landing / intro page\n",
      "\n",
      "testelapse  The time in seconds spent on the page with the survey questions\n",
      "\n",
      "endelapse   The time in seconds spent on the finalization page (where the user was asked to indicate if they has answered accurately and their answers could be stored and used for research. Again: this dataset only includes users who answered \"Yes\" to this question, users were free to answer no and could still view their results either way)\n",
      "\n",
      "IPC         The number of records from the user's IP address in the dataset. For max cleanliness, only use records where this value is 1. High values can be because of shared networks (e.g. entire universities) or multiple submissions\n",
      "\n",
      "country     The country, determined by technical information (NOT ASKED AS A QUESTION)\n",
      "\n",
      "lat_appx_lots_of_err    approximate latitude of user. determined by technical information, THIS IS NOT VERY ACCURATE. Read the article \"How an internet mapping glitch turned a random Kansas farm into a digital hell\" https://splinternews.com/how-an-internet-mapping-glitch-turned-a-random-kansas-f-1793856052 to learn about the perils of relying on this information\n",
      "\n",
      "long_appx_lots_of_err   approximate longitude of user\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('./data/codebook.txt', \"r\")\n",
    "for line in f:\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to single IP address use only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the codebook.txt file, there are instances where an IP address is used more than once (column 'IPC') to complete the questionaire. This could indicate multiple submissions from the same person or submissions over a shared network (e.g. a university). As seen below, there are nearly 700K instances where the IP address has only been used once. As suggested in the codebook.txt file, I will only use these instances in the remaining analyses for maximum cleanliness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      696845\n",
       "2      105868\n",
       "3       34323\n",
       "4       17332\n",
       "5       11135\n",
       "        ...  \n",
       "103       103\n",
       "99         99\n",
       "98         98\n",
       "88         88\n",
       "87         87\n",
       "Name: IPC, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IPC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696845"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_IP_df = df.copy()\n",
    "single_IP_df = single_IP_df.loc[single_IP_df['IPC'] == 1]\n",
    "len(single_IP_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversing scores on negatively keyed items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the link to the [IPIP website](https://ipip.ori.org/newBigFive5broadKey.htm) provided in the codebook.txt file, we can see that some of the questions are negatively keyed. For example, item EXT2 in the online questionnaire results is \"I don't talk a lot\" - as this is a measure of extraversion, we would expect someone high in extraversion to disagree with this statement and provide a low score on the scale of 1-5 (1=Disagree, 3=Neutral, and 5=Agree). If this is compared to item EXT1 (\"I am the life of the party\"), we would expect someone high in extraversion to agree with this statement and provide a high score on the scale of 1-5. As a result, some of the scores in the dataset need to be reversed so that the scores consistently indicate each personality trait (e.g. high scores on the EXT items indicate a tendency towards being high in extraversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_keyed_items = [\n",
    "    'EXT2', \n",
    "    'EXT4', \n",
    "    'EXT6',\n",
    "    'EXT8',\n",
    "    'EXT10', \n",
    "    \n",
    "    'EST1',\n",
    "    'EST3',\n",
    "    'EST5',\n",
    "    'EST6',\n",
    "    'EST7',\n",
    "    'EST8',\n",
    "    'EST9',\n",
    "    'EST10',\n",
    "    \n",
    "    'AGR1',\n",
    "    'AGR3',\n",
    "    'AGR5',\n",
    "    'AGR7',\n",
    "    \n",
    "    'CSN2',\n",
    "    'CSN4',\n",
    "    'CSN6',\n",
    "    'CSN8',\n",
    "    \n",
    "    'OPN2',\n",
    "    'OPN4',\n",
    "    'OPN6'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>dateload</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>IPC</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:01</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.5448</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:20</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>MY</td>\n",
       "      <td>3.1698</td>\n",
       "      <td>101.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:56</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>54.9119</td>\n",
       "      <td>-1.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:02:02</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.75</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:03:12</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.3333</td>\n",
       "      <td>18.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
       "0   4.0   5.0   5.0   4.0   5.0   5.0   5.0   4.0   4.0    5.0  ...   \n",
       "1   3.0   1.0   3.0   2.0   3.0   3.0   2.0   1.0   1.0    1.0  ...   \n",
       "2   2.0   3.0   4.0   2.0   3.0   4.0   1.0   3.0   2.0    1.0  ...   \n",
       "3   2.0   4.0   2.0   3.0   4.0   4.0   2.0   2.0   1.0    2.0  ...   \n",
       "5   3.0   3.0   4.0   4.0   4.0   4.0   2.0   3.0   3.0    2.0  ...   \n",
       "\n",
       "              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n",
       "0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n",
       "1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n",
       "2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n",
       "3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n",
       "5  2016-03-03 02:03:12   1600.0   1000.0          4.0       196.0          3   \n",
       "\n",
       "   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "0    1       GB               51.5448                 0.1991  \n",
       "1    1       MY                3.1698                101.706  \n",
       "2    1       GB               54.9119                -1.3833  \n",
       "3    1       GB                 51.75                  -1.25  \n",
       "5    1       SE               59.3333                  18.05  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_df = single_IP_df.copy()\n",
    "adj_df[neg_keyed_items] = adj_df[neg_keyed_items].apply(lambda x: x.map({1.0:5.0, 2.0:4.0, 3.0:3.0, 4.0:2.0, 5.0:1.0}))\n",
    "adj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696845"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_5_personality_test",
   "language": "python",
   "name": "big_5_personality_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
